<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Recorder</title>
    <!-- Google Fonts: Inter -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #007AFF;
            --danger: #FF3B30;
            --gray-100: #F2F2F7;
            --gray-800: #1C1C1E;
            --glass-bg: rgba(255, 255, 255, 0.65);
            --glass-border: rgba(255, 255, 255, 0.4);
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            height: 100vh;
            margin: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            color: var(--gray-800);
            overflow: hidden;
        }

        .container {
            width: 100%;
            max-width: 420px;
            padding: 40px;
            background: var(--glass-bg);
            backdrop-filter: blur(20px);
            -webkit-backdrop-filter: blur(20px);
            border-radius: 24px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.05);
            border: 1px solid var(--glass-border);
            text-align: center;
            transition: transform 0.3s ease;
        }

        h1 {
            font-weight: 600;
            font-size: 24px;
            margin-bottom: 8px;
            letter-spacing: -0.5px;
        }

        p.subtitle {
            color: #666;
            font-size: 14px;
            margin-bottom: 32px;
        }

        /* Language Selector */
        .select-wrapper {
            position: relative;
            margin-bottom: 32px;
        }

        select {
            appearance: none;
            width: 100%;
            padding: 12px 16px;
            font-size: 16px;
            font-family: inherit;
            background: rgba(255, 255, 255, 0.8);
            border: 1px solid rgba(0, 0, 0, 0.1);
            border-radius: 12px;
            color: var(--gray-800);
            cursor: pointer;
            transition: all 0.2s ease;
            outline: none;
        }

        select:hover {
            border-color: rgba(0, 0, 0, 0.2);
        }

        select:focus {
            border-color: var(--primary);
            box-shadow: 0 0 0 3px rgba(0, 122, 255, 0.1);
        }

        /* Microphone Button */
        .mic-btn-container {
            display: flex;
            justify-content: center;
            margin-bottom: 32px;
        }

        .mic-btn {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            background: #fff;
            border: none;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
            position: relative;
        }

        .mic-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 16px rgba(0, 0, 0, 0.12);
        }

        .mic-btn svg {
            width: 32px;
            height: 32px;
            fill: var(--primary);
            transition: fill 0.3s ease;
        }

        .mic-btn.recording {
            animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
            background: var(--danger);
        }

        .mic-btn.recording svg {
            fill: #fff;
        }

        @keyframes pulse-ring {
            0% {
                box-shadow: 0 0 0 0 rgba(255, 59, 48, 0.7);
            }

            70% {
                box-shadow: 0 0 0 20px rgba(255, 59, 48, 0);
            }

            100% {
                box-shadow: 0 0 0 0 rgba(255, 59, 48, 0);
            }
        }

        /* Status & Result */
        #status {
            font-size: 14px;
            font-weight: 500;
            height: 20px;
            color: #888;
            margin-bottom: 24px;
        }

        #result {
            min-height: 80px;
            max-height: 400px;
            overflow-y: auto;
            padding: 16px;
            background: rgba(255, 255, 255, 0.5);
            border-radius: 12px;
            border: 1px solid rgba(0, 0, 0, 0.05);
            font-size: 16px;
            line-height: 1.5;
            color: var(--gray-800);
            text-align: left;
            word-wrap: break-word;
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .loader {
            display: none;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(0, 122, 255, 0.2);
            border-top-color: var(--primary);
            border-radius: 50%;
            animation: spin 0.8s linear infinite;
            margin: 0 auto 16px auto;
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }
    </style>
</head>

<body>

    <div class="container">
        <h1>IndicRecorder</h1>
        <p class="subtitle">AI-Powered Speech to Text</p>

        <div class="select-wrapper">
            <select id="language">
                <option value="ne">Nepali (नेपाली)</option>
                <option value="hi" selected>Hindi (हिंदी)</option>
                <option value="mai">Maithili (मैथिली)</option>
            </select>
        </div>

        <div class="mic-btn-container">
            <button id="recordBtn" class="mic-btn">
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z" />
                    <path
                        d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z" />
                </svg>
            </button>
        </div>

        <div id="status">Tap microphone to start</div>
        <div class="loader" id="loader"></div>
        <div id="result"></div>
    </div>

    <script>
        const recordBtn = document.getElementById('recordBtn');
        const statusEl = document.getElementById('status');
        const resultEl = document.getElementById('result');
        const loader = document.getElementById('loader');
        const langSelect = document.getElementById('language');

        let isRecording = false;
        let audioContext;
        let processor;
        let input;
        let globalStream;
        let websocket;

        const TARGET_SAMPLE_RATE = 16000;

        // Connect immediately on load to receive broadcasts
        connectWebSocket();

        recordBtn.addEventListener('click', async () => {
            if (!isRecording) {
                startAudioCapture();
            } else {
                stopAudioCapture();
            }
        });

        langSelect.addEventListener('change', () => {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({
                    type: "config",
                    language: langSelect.value
                }));
            }
        });

        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            // We don't send lang in URL anymore, we wait for config or sync
            const wsUrl = `${protocol}//${window.location.host}/transcribe/ws`;

            websocket = new WebSocket(wsUrl);

            websocket.onopen = () => {
                console.log("Connected to Control Stream");
                statusEl.textContent = "Connected (Monitoring)";
                statusEl.style.color = "#007AFF";
            };

            websocket.onmessage = (event) => {
                const data = JSON.parse(event.data);

                if (data.type === 'transcription' && data.text) {
                    // Append new text with a space
                    resultEl.textContent += (resultEl.textContent ? " " : "") + data.text;
                    resultEl.scrollTop = resultEl.scrollHeight;
                }

                if (data.type === 'config' && data.language) {
                    // Update our dropdown to match server state
                    langSelect.value = data.language;
                    console.log("Synced language to:", data.language);
                }
            };

            websocket.onerror = (error) => {
                console.error("WS Error:", error);
                statusEl.textContent = "Connection Error";
            };

            websocket.onclose = () => {
                statusEl.textContent = "Disconnected. Reconnecting...";
                setTimeout(connectWebSocket, 3000);
            };
        }

        async function startAudioCapture() {
            try {
                if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                    alert("Not connected to server!");
                    return;
                }

                // 1. Get Microphone
                globalStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // 2. Setup Audio Context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                input = audioContext.createMediaStreamSource(globalStream);

                // Start processing audio
                setupAudioProcessor();

                isRecording = true;
                recordBtn.classList.add('recording');
                statusEl.textContent = "Broadcasting Audio...";
                statusEl.style.color = "#FF3B30";

            } catch (err) {
                console.error("Mic access denied:", err);
                statusEl.textContent = "Microphone access denied.";
            }
        }

        function setupAudioProcessor() {
            // Buffer size 4096 is a good balance
            processor = audioContext.createScriptProcessor(4096, 1, 1);

            input.connect(processor);
            processor.connect(audioContext.destination);

            processor.onaudioprocess = (e) => {
                if (!isRecording || websocket.readyState !== WebSocket.OPEN) return;

                const inputData = e.inputBuffer.getChannelData(0);
                const downsampledBuffer = downsampleBuffer(inputData, audioContext.sampleRate, TARGET_SAMPLE_RATE);
                const pcmData = floatTo16BitPCM(downsampledBuffer);

                // Send raw int16 bytes
                websocket.send(pcmData);
            };
        }

        function floatTo16BitPCM(input) {
            const output = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                const s = Math.max(-1, Math.min(1, input[i]));
                output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return output;
        }

        function downsampleBuffer(buffer, sampleRate, outSampleRate) {
            if (outSampleRate === sampleRate) {
                return buffer;
            }
            if (outSampleRate > sampleRate) {
                throw "Downsampling only";
            }
            const sampleRateRatio = sampleRate / outSampleRate;
            const newLength = Math.round(buffer.length / sampleRateRatio);
            const result = new Float32Array(newLength);
            let offsetResult = 0;
            let offsetBuffer = 0;
            while (offsetResult < result.length) {
                const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                // Simple averaging (box filter) to avoid aliasing
                let accum = 0, count = 0;
                for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }
                result[offsetResult] = accum / count;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result;
        }

        function stopAudioCapture() {
            isRecording = false;
            recordBtn.classList.remove('recording');
            statusEl.textContent = "Connected (Monitoring)";
            statusEl.style.color = "#007AFF";

            // Stop tracks
            if (globalStream) {
                globalStream.getTracks().forEach(track => track.stop());
            }
            // Disconnect audio nodes
            if (processor && input) {
                input.disconnect();
                processor.disconnect();
            }
            if (audioContext) {
                audioContext.close();
            }
        }
    </script>
</body>

</html>